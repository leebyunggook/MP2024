{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import imutils\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import mp_utils as mu\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from imutils.object_detection import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mediapipe Face - camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps using camera id = 1  : 30\n"
     ]
    }
   ],
   "source": [
    "width, height = 1024, 768\n",
    "cap, fps = mu.setCamera(1, width, height)\n",
    "\n",
    "debug = False\n",
    "displayScale = 1\n",
    "kIndex = np.array([[54, 10, 8, 162], [162, 8, 5, 93], [93, 5, 17, 58], [58, 17, 152, 150], [10, 284, 389, 8], [8, 389, 323, 5], [5, 323, 288, 17], [17, 288, 379, 152]])\n",
    "\n",
    "cv2.namedWindow(\"origin\", cv2.WINDOW_NORMAL)  \n",
    "cv2.namedWindow(\"swap\", cv2.WINDOW_NORMAL)  \n",
    "cv2.resizeWindow(\"origin\", (int)(width/displayScale), (int)(height/displayScale))  \n",
    "cv2.resizeWindow(\"swap\", (int)(width/displayScale), (int)(height/displayScale))\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "radius = 2\n",
    "thickness = 1\n",
    "color = (0, 0, 255)\n",
    "frameCount = 0\n",
    "type = 0\n",
    "\n",
    "start = time.time()\n",
    "delay_time = int(1000/fps)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=2, \n",
    "  refine_landmarks=True, min_detection_confidence=0.5) as face_mesh:  \n",
    "  while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "      continue\n",
    "\n",
    "    frameCount += 1\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "    frame.flags.writeable = False\n",
    "    results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    annotated_image = frame.copy()\n",
    "    pannotated_image = frame.copy()\n",
    "    count = 0\n",
    "    if results.multi_face_landmarks:\n",
    "      for face_landmarks in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(image=annotated_image, landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_TESSELATION, landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "        count += 1  \n",
    "  \n",
    "    if count == 2:\n",
    "      pannotated_image = mu.kLocalPerspective(pannotated_image, kIndex, results, type, debug)\n",
    "\n",
    "    mu.debugFrameMessage(annotated_image, font, frameCount, start, type)\n",
    "\n",
    "    cv2.imshow(\"origin\", annotated_image)\n",
    "    cv2.imshow(\"swap\", pannotated_image)\n",
    "\n",
    "    key = cv2.waitKey(delay_time) & 0xFF\n",
    "    if key == ord('q') or key == 27:\n",
    "      break\n",
    "    elif key == ord(' '):\n",
    "      type += 1\n",
    "      if type > 2: \n",
    "        type = 0\n",
    "  cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mediapipe Face - image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 .\\image\\2_faces_2.jpg\n",
      "1 .\\image\\2_faces.jpg\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "displayScale = 1\n",
    "kIndex = np.array([[21, 10, 152, 136], [10, 251, 365, 152]])\n",
    "cv2.namedWindow(\"origin\", cv2.WINDOW_NORMAL)  \n",
    "cv2.namedWindow(\"swap\", cv2.WINDOW_NORMAL)  \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "IMAGE_FILES = [\".\\\\image\\\\2_faces_2.jpg\", \".\\\\image\\\\2_faces.jpg\"] #, \".\\\\image\\\\2_faces.jpg\"\n",
    "\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=2,\n",
    "  refine_landmarks=True, min_detection_confidence=0.5) as face_mesh:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    height, width, _ = image.shape\n",
    "    cv2.resizeWindow(\"origin\", (int)(width/displayScale), (int)(height/displayScale))  \n",
    "    cv2.resizeWindow(\"swap\", (int)(width/displayScale), (int)(height/displayScale))  \n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    annotated_image = image.copy()\n",
    "    pannotated_image = image.copy()\n",
    "    if results.multi_face_landmarks:\n",
    "      for face_landmarks in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(image=annotated_image, landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_TESSELATION, landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "  \n",
    "      # pannotated_image = localPerspective(annotated_image, results)\n",
    "      pannotated_image = mu.kLocalPerspective(annotated_image, kIndex, results, 2, debug)\n",
    "      cv2.imshow(\"origin\", annotated_image)\n",
    "      cv2.imshow(\"swap\", pannotated_image)\n",
    "      cv2.waitKey(0)\n",
    "      print(idx, file)    \n",
    "  cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera Test Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mu.cameraIndexes(3)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./image/2_faces_2.jpg')\n",
    "cv2.namedWindow('origin', cv2.WINDOW_NORMAL)  \n",
    "cv2.imshow('origin', image)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.float32([[10,10],[80,10],[80,30],[10,30]]) #(y, x)\n",
    "print(pts.shape)\n",
    "print(pts[:,1], pts[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\".\\\\image\\\\opencv.png\")\n",
    "pts1 = np.float32([[56,65],[368,52],[389,390],[28,387]])\n",
    "pts2 = np.float32([[600,100],[900,100],[850,490],[600,500]])\n",
    "cond = mu.bpoly2mask(pts[:,1], pts[:,0], image.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks,\n",
    "#   connections=mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=None,\n",
    "#   connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "# mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks,\n",
    "#   connections=mp_face_mesh.FACEMESH_IRISES, landmark_drawing_spec=None,\n",
    "#   connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('siif2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e7966373603db941a10f4886aef93af4ca94252cee91c5bb3234de2275e1985"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
